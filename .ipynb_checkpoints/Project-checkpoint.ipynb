{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e5d62c",
   "metadata": {},
   "source": [
    "# <center> **Audio Classification using Deep Learning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4d12a",
   "metadata": {
    "id": "G5LoX1O61v8v"
   },
   "source": [
    "# **Introduction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-element",
   "metadata": {
    "papermill": {
     "duration": 0.013982,
     "end_time": "2021-05-18T13:45:42.795693",
     "exception": false,
     "start_time": "2021-05-18T13:45:42.781711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing the required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fancy-edmonton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T13:45:42.835137Z",
     "iopub.status.busy": "2021-05-18T13:45:42.834459Z",
     "iopub.status.idle": "2021-05-18T13:45:49.403706Z",
     "shell.execute_reply": "2021-05-18T13:45:49.402732Z"
    },
    "papermill": {
     "duration": 6.594003,
     "end_time": "2021-05-18T13:45:49.403865",
     "exception": false,
     "start_time": "2021-05-18T13:45:42.809862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     Dense,\n\u001b[0;32m     16\u001b[0m     Conv1D,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     MaxPool2D,\n\u001b[0;32m     23\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import os, time, warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cols = [\"model\", \"accuracy\", \"train_time\", \"pred_time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-resort",
   "metadata": {
    "papermill": {
     "duration": 0.014401,
     "end_time": "2021-05-18T13:45:49.434477",
     "exception": false,
     "start_time": "2021-05-18T13:45:49.420076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-momentum",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T13:45:49.470452Z",
     "iopub.status.busy": "2021-05-18T13:45:49.469965Z",
     "iopub.status.idle": "2021-05-18T13:45:49.513057Z",
     "shell.execute_reply": "2021-05-18T13:45:49.513481Z"
    },
    "papermill": {
     "duration": 0.064841,
     "end_time": "2021-05-18T13:45:49.513660",
     "exception": false,
     "start_time": "2021-05-18T13:45:49.448819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the files\n",
    "audio_dataset_path = \"C:/Users/ASUS/Untitled Folder/Sample-TA/datasets/train/audio/\"\n",
    "\n",
    "# loading the csv\n",
    "meta_data = pd.read_csv(\"C:/Users/ASUS/Untitled Folder/Sample-TA/datasets/train/audio/Fraud.csv\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(\n",
    "    to_replace=\"_background_noise_\", value=\"Background Noise\"\n",
    ")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"ehmm\", value=\"Dehem\")\n",
    "meta_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data.groupby(\"classID\")[\"class\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb434592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "x = meta_data[\"class\"].unique()\n",
    "y = meta_data[\"class\"].value_counts(ascending=True)\n",
    "ind = np.arange(len(y))\n",
    "# plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.barh(ind, y)\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(x)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.gcf().set_dpi(500)\n",
    "plt.title(\"Number of Audio Samples per Category\")\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba499520",
   "metadata": {},
   "source": [
    "# **MFCC Visualization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e69ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (4, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7577b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "VQw82jldrf_M",
    "outputId": "f810e937-b579-4493-9ffb-9ceb96fc32b4"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold5/h 009.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Dehem\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3aff8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "RI0ctX4ivRxo",
    "outputId": "77d75bef-776d-452d-ff85-586b20f36f15"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/doing_the_dishes.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Noise\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e2a8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "Xk5q4aycvcEJ",
    "outputId": "59979696-6c36-4c92-928a-1f01c5b254f0"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/105415-2-0-1.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Children Playing\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0a4f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "QYhwX2sAvmW4",
    "outputId": "8d2e828f-70a5-4954-9ca9-a82c77869a05"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/101415-3-0-2.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Dog Bark\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b549b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "FlUon7eHvxkR",
    "outputId": "c9302211-bf89-4d01-9dd8-1eef1a8c021b"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/14113-4-0-0.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Drilling\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05287049",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "xPfjm3Y5v65A",
    "outputId": "f78c53d4-4184-4c01-f68e-7b4de53b0bbd"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/103258-5-0-0.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Engine Idling\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d563e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "ZaRm4peXwD5Y",
    "outputId": "bfd12ec3-b1ea-40ff-884a-7adff0adfcf9"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/102305-6-0-0.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Gun Shot\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8baf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "-xvUladnwMVP",
    "outputId": "a4538066-79f8-420b-e51f-9caebf0a7d3a"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/103074-7-0-0.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Jack Hammer\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76125059",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "7h-Sv2zrwW8w",
    "outputId": "b592d7e7-fec3-45e7-c79f-9fc40bf3cb52"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/106905-8-0-0.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Siren\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64420ff7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "wuXSJ8RTwfGf",
    "outputId": "7d1d27c5-b991-4776-e1e9-e868508329de"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"fold1/108041-9-0-11.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Street Music\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91111924",
   "metadata": {},
   "source": [
    "# **Feature Extraction and Database Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570532f",
   "metadata": {
    "id": "u0i6SlEzEYjM"
   },
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb482c",
   "metadata": {},
   "source": [
    "1. I have used Librosa to preprocess audio file.\n",
    "2. To do so, I will go through each fold and extract the data from each file using librosa's mfcc function.\n",
    "3. The extracted data is appended in a list and stored in a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8784b67",
   "metadata": {
    "id": "YGO837s_1v9K"
   },
   "source": [
    "### The function bellow will extract mfcc feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62202b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing all the features\n",
    "extracted = []\n",
    "\n",
    "# for each row in the csv\n",
    "for index_num, row in tqdm(meta_data.iterrows()):\n",
    "    # get the file\n",
    "    file_name = os.path.join(\n",
    "        os.path.abspath(audio_dataset_path),\n",
    "        \"fold\" + str(row[\"fold\"]) + \"/\",\n",
    "        str(row[\"slice_file_name\"]),\n",
    "    )\n",
    "    # get file label\n",
    "    final_class_labels = row[\"class\"]\n",
    "    # load the audio file\n",
    "    audio, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    # extract the features\n",
    "    feature = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=128)\n",
    "    # feature scaling\n",
    "    scaled_feature = np.mean(feature.T, axis=0)\n",
    "    # store it in a list\n",
    "    extracted.append([scaled_feature, final_class_labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-coast",
   "metadata": {
    "papermill": {
     "duration": 1.548527,
     "end_time": "2021-05-18T14:01:07.480813",
     "exception": false,
     "start_time": "2021-05-18T14:01:05.932286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Using a dataframe and pickle to save the extracted features array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-clear",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:10.903218Z",
     "iopub.status.busy": "2021-05-18T14:01:10.902488Z",
     "iopub.status.idle": "2021-05-18T14:01:10.905456Z",
     "shell.execute_reply": "2021-05-18T14:01:10.905894Z"
    },
    "papermill": {
     "duration": 1.818786,
     "end_time": "2021-05-18T14:01:10.906028",
     "exception": false,
     "start_time": "2021-05-18T14:01:09.087242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new dataframe\n",
    "extracted_df = pd.DataFrame(extracted, columns=[\"feature\", \"class\"])\n",
    "# Storing the dataframe to pickle for further processing\n",
    "extracted_df.to_pickle(\"extracted_df.pkl\")\n",
    "extracted_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd97538",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-oxide",
   "metadata": {
    "papermill": {
     "duration": 1.556269,
     "end_time": "2021-05-18T14:01:14.010539",
     "exception": false,
     "start_time": "2021-05-18T14:01:12.454270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Distribute the data to X and Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_pickle(\"extracted_df.pkl\")\n",
    "X = np.array(final[\"feature\"].tolist())\n",
    "y = np.array(final[\"class\"].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-genius",
   "metadata": {
    "papermill": {
     "duration": 1.6095,
     "end_time": "2021-05-18T14:01:20.316376",
     "exception": false,
     "start_time": "2021-05-18T14:01:18.706876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using LabelEncoder() to encode the string labels to an integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-state",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:23.681388Z",
     "iopub.status.busy": "2021-05-18T14:01:23.680865Z",
     "iopub.status.idle": "2021-05-18T14:01:23.684868Z",
     "shell.execute_reply": "2021-05-18T14:01:23.684397Z"
    },
    "papermill": {
     "duration": 1.583578,
     "end_time": "2021-05-18T14:01:23.684982",
     "exception": false,
     "start_time": "2021-05-18T14:01:22.101404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label encoding to get encoding\n",
    "le = LabelEncoder()\n",
    "\n",
    "# transform each category with it's respected label\n",
    "Y = to_categorical(le.fit_transform(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-discharge",
   "metadata": {
    "papermill": {
     "duration": 1.572854,
     "end_time": "2021-05-18T14:01:26.836045",
     "exception": false,
     "start_time": "2021-05-18T14:01:25.263191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split the data into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-graphics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:30.528635Z",
     "iopub.status.busy": "2021-05-18T14:01:30.527743Z",
     "iopub.status.idle": "2021-05-18T14:01:30.535830Z",
     "shell.execute_reply": "2021-05-18T14:01:30.535190Z"
    },
    "papermill": {
     "duration": 1.646809,
     "end_time": "2021-05-18T14:01:30.536014",
     "exception": false,
     "start_time": "2021-05-18T14:01:28.889205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# print the details\n",
    "print(\"Number of training samples = \", X_train.shape[0])\n",
    "print(\"Number of testing samples = \", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e753d4",
   "metadata": {},
   "source": [
    "# **Model 1 - ANN**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-render",
   "metadata": {
    "papermill": {
     "duration": 1.581455,
     "end_time": "2021-05-18T14:01:33.935793",
     "exception": false,
     "start_time": "2021-05-18T14:01:32.354338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-machine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:37.118145Z",
     "iopub.status.busy": "2021-05-18T14:01:37.117610Z",
     "iopub.status.idle": "2021-05-18T14:01:39.261039Z",
     "shell.execute_reply": "2021-05-18T14:01:39.260076Z"
    },
    "papermill": {
     "duration": 3.742495,
     "end_time": "2021-05-18T14:01:39.261194",
     "exception": false,
     "start_time": "2021-05-18T14:01:35.518699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "\n",
    "num_labels = Y.shape[1]\n",
    "ANN_Model = Sequential()\n",
    "ANN_Model.add(Dense(1000, activation=\"relu\", input_shape=(128,)))\n",
    "ANN_Model.add(Dense(750, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(500, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(250, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(100, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(50, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "ANN_Model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-transportation",
   "metadata": {
    "papermill": {
     "duration": 1.71757,
     "end_time": "2021-05-18T14:01:42.553695",
     "exception": false,
     "start_time": "2021-05-18T14:01:40.836125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compiling the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-benchmark",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:45.785340Z",
     "iopub.status.busy": "2021-05-18T14:01:45.784541Z",
     "iopub.status.idle": "2021-05-18T14:01:45.791383Z",
     "shell.execute_reply": "2021-05-18T14:01:45.791916Z"
    },
    "papermill": {
     "duration": 1.570325,
     "end_time": "2021-05-18T14:01:45.792052",
     "exception": false,
     "start_time": "2021-05-18T14:01:44.221727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ANN_Model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-machinery",
   "metadata": {
    "papermill": {
     "duration": 1.560171,
     "end_time": "2021-05-18T14:01:48.907097",
     "exception": false,
     "start_time": "2021-05-18T14:01:47.346926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-metabolism",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:52.113048Z",
     "iopub.status.busy": "2021-05-18T14:01:52.112508Z",
     "iopub.status.idle": "2021-05-18T14:03:33.704926Z",
     "shell.execute_reply": "2021-05-18T14:03:33.663057Z"
    },
    "papermill": {
     "duration": 103.168786,
     "end_time": "2021-05-18T14:03:33.705066",
     "exception": false,
     "start_time": "2021-05-18T14:01:50.536280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 250\n",
    "num_batch_size = 32\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "ANN_Results = ANN_Model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=num_batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    ")\n",
    "\n",
    "ANN_Model.save(\"Model1.h5\")\n",
    "print(\"ANN Model Saved\")\n",
    "train_hist_m1 = pd.DataFrame(ANN_Results.history)\n",
    "train_m1 = round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b404021",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m1[[\"loss\", \"val_loss\"]])\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a27e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m1[[\"accuracy\", \"val_accuracy\"]])\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.title(\"Accuracy Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m1 = ANN_Model.evaluate(X_test, y_test, verbose=0)\n",
    "t0 = time.time()\n",
    "y_pred_m1 = ANN_Model.predict(X_test, verbose=0)\n",
    "pred_m1 = round(time.time() - t0, 3)\n",
    "log_entry = pd.DataFrame(\n",
    "    [[\"ANN\", acc_m1[1] * 100, train_m1, pred_m1]], columns=log_cols\n",
    ")\n",
    "log = log.append(log_entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-julian",
   "metadata": {
    "papermill": {
     "duration": 2.034009,
     "end_time": "2021-05-18T14:03:41.813463",
     "exception": false,
     "start_time": "2021-05-18T14:03:39.779454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ANN Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict the feature\n",
    "def ANN_Prediction(file_name):\n",
    "    # load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    # get the feature\n",
    "    feature = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=128)\n",
    "    # scale the features\n",
    "    feature_scaled = np.mean(feature.T, axis=0)\n",
    "    # array of features\n",
    "    prediction_feature = np.array([feature_scaled])\n",
    "    # get the id of label using argmax\n",
    "    predicted_vector = np.argmax(ANN_Model.predict(prediction_feature), axis=-1)\n",
    "    # get the class label from class id\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    # display the result\n",
    "    print(\"ANN has predicted the class as  --> \", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-charles",
   "metadata": {
    "papermill": {
     "duration": 2.014985,
     "end_time": "2021-05-18T14:03:59.338044",
     "exception": false,
     "start_time": "2021-05-18T14:03:57.323059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e0ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name\n",
    "file_name = audio_dataset_path + \"fold8/103076-3-0-0.wav\"\n",
    "# get the output\n",
    "ANN_Prediction(file_name)\n",
    "# play the file\n",
    "ipd.Audio(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745bc49",
   "metadata": {},
   "source": [
    "# **Model 2 - CNN1D**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ecf18",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea002582",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainval, xTest, yTrainval, yTest = train_test_split(\n",
    "    X, Y, test_size=0.1, stratify=y, random_state=387\n",
    ")\n",
    "xTrain, xvalid, yTrain, yvalid = train_test_split(\n",
    "    xTrainval, yTrainval, test_size=0.2, stratify=yTrainval, random_state=387\n",
    ")\n",
    "print(\"\\nNumber of samples for Train set :\", xTrain.shape[0])\n",
    "print(\"Number of samples for Validation set :\", xvalid.shape[0])\n",
    "print(\"Number of samples for Test set :\", xTest.shape[0])\n",
    "\n",
    "xTrain = np.expand_dims(xTrain, axis=2)\n",
    "xvalid = np.expand_dims(xvalid, axis=2)\n",
    "\n",
    "print(\"Shape of X Train\", xTrain.shape)\n",
    "print(\"Shape of X Test\", xTest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ec0b7",
   "metadata": {},
   "source": [
    "## Building the CNN1D Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN1D_Model = Sequential()\n",
    "CNN1D_Model.add(\n",
    "    Conv1D(\n",
    "        256,\n",
    "        5,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        input_shape=(xTrain.shape[1], 1),\n",
    "    )\n",
    ")\n",
    "CNN1D_Model.add(BatchNormalization())\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Conv1D(256, 5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Conv1D(128, 5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Conv1D(64, 5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Flatten())\n",
    "CNN1D_Model.add(Dense(units=1024, activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(Dense(units=10, activation=\"softmax\"))\n",
    "CNN1D_Model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ec5b1",
   "metadata": {},
   "source": [
    "## Compiling the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff66d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN1D_Model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c6d28",
   "metadata": {},
   "source": [
    "## Fitting the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6099ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "CNN1D_Results = CNN1D_Model.fit(\n",
    "    xTrain, yTrain, batch_size=64, epochs=250, validation_data=(xvalid, yvalid)\n",
    ")\n",
    "\n",
    "CNN1D_Model.save(\"Model2.h5\")\n",
    "print(\"CNN1D Model Saved\")\n",
    "train_hist_m2 = pd.DataFrame(CNN1D_Results.history)\n",
    "train_m2 = round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e51a14",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m2[[\"loss\", \"val_loss\"]])\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m2[[\"accuracy\", \"val_accuracy\"]])\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.title(\"Accuracy Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m2 = CNN1D_Model.evaluate(xvalid, yvalid, verbose=0)\n",
    "t0 = time.time()\n",
    "y_pred_m2 = CNN1D_Model.predict(xvalid, verbose=0)\n",
    "pred_m2 = round(time.time() - t0, 3)\n",
    "log_entry = pd.DataFrame(\n",
    "    [[\"CNN1D\", acc_m2[1] * 100, train_m2, pred_m2]], columns=log_cols\n",
    ")\n",
    "log = log.append(log_entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860863ed",
   "metadata": {
    "papermill": {
     "duration": 2.034009,
     "end_time": "2021-05-18T14:03:41.813463",
     "exception": false,
     "start_time": "2021-05-18T14:03:39.779454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN1D Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict the feature\n",
    "def CNN1D_Prediction(file_name):\n",
    "    # load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    # get the feature\n",
    "    feature = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=128)\n",
    "    # scale the features\n",
    "    feature_scaled = np.mean(feature.T, axis=0)\n",
    "    # array of features\n",
    "    prediction_feature = np.array([feature_scaled])\n",
    "    # expand dims\n",
    "    final_prediction_feature = np.expand_dims(prediction_feature, axis=2)\n",
    "    # get the id of label using argmax\n",
    "    predicted_vector = np.argmax(CNN1D_Model.predict(final_prediction_feature), axis=-1)\n",
    "    # get the class label from class id\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    # display the result\n",
    "    print(\"CNN1D has predicted the class as  --> \", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef8d35",
   "metadata": {
    "papermill": {
     "duration": 2.014985,
     "end_time": "2021-05-18T14:03:59.338044",
     "exception": false,
     "start_time": "2021-05-18T14:03:57.323059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-adams",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:04:03.459573Z",
     "iopub.status.busy": "2021-05-18T14:04:03.459043Z",
     "iopub.status.idle": "2021-05-18T14:04:03.674741Z",
     "shell.execute_reply": "2021-05-18T14:04:03.675143Z"
    },
    "papermill": {
     "duration": 2.315011,
     "end_time": "2021-05-18T14:04:03.675281",
     "exception": false,
     "start_time": "2021-05-18T14:04:01.360270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File name\n",
    "file_name = audio_dataset_path + \"fold8/103076-3-0-0.wav\"\n",
    "# get the output\n",
    "CNN1D_Prediction(file_name)\n",
    "# play the file\n",
    "ipd.Audio(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4617b9c",
   "metadata": {},
   "source": [
    "# **Model 3 - CNN2D**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b209cf",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82493c6e",
   "metadata": {
    "id": "0LMzRMVo2bCD"
   },
   "outputs": [],
   "source": [
    "xtrain = xTrain.reshape(xTrain.shape[0], 16, 8, 1)\n",
    "xtest = xTest.reshape(xTest.shape[0], 16, 8, 1)\n",
    "\n",
    "print(\"The Shape of X Train\", xtrain.shape)\n",
    "print(\"The Shape of Y Train\", yTrain.shape)\n",
    "print(\"The Shape of X Test\", xtest.shape)\n",
    "print(\"The Shape of Y Test\", yTest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bef3cce",
   "metadata": {},
   "source": [
    "## Building the CNN2D Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5086721",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1637997095857,
     "user": {
      "displayName": "ABISHEK A S 18MIS1077",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJZSUo6yw767eDfc3wD650IKPldCKqUI_SXaz00Q=s64",
      "userId": "03792549481302978685"
     },
     "user_tz": -330
    },
    "id": "uo2y-FV22nCD",
    "outputId": "41cc8e28-95c5-4ed7-8128-50779a8f27cf"
   },
   "outputs": [],
   "source": [
    "CNN2D_Model = Sequential()\n",
    "CNN2D_Model.add(\n",
    "    Conv2D(64, (3, 3), padding=\"same\", activation=\"tanh\", input_shape=(16, 8, 1))\n",
    ")\n",
    "CNN2D_Model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "CNN2D_Model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"tanh\"))\n",
    "CNN2D_Model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "CNN2D_Model.add(Dropout(0.1))\n",
    "CNN2D_Model.add(Flatten())\n",
    "CNN2D_Model.add(Dense(1024, activation=\"tanh\"))\n",
    "CNN2D_Model.add(Dense(10, activation=\"softmax\"))\n",
    "CNN2D_Model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a81586",
   "metadata": {},
   "source": [
    "## Compiling the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN2D_Model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6de7af",
   "metadata": {},
   "source": [
    "## Fitting the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464f12d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309565,
     "status": "ok",
     "timestamp": 1637997405415,
     "user": {
      "displayName": "ABISHEK A S 18MIS1077",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJZSUo6yw767eDfc3wD650IKPldCKqUI_SXaz00Q=s64",
      "userId": "03792549481302978685"
     },
     "user_tz": -330
    },
    "id": "rwvYK12q2pHy",
    "outputId": "f9c04b9b-67ca-4c5a-a090-443399934ab1"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "CNN2D_Results = CNN2D_Model.fit(\n",
    "    xtrain, yTrain, epochs=250, batch_size=50, validation_data=(xtest, yTest)\n",
    ")\n",
    "\n",
    "CNN2D_Model.save(\"Model3.h5\")\n",
    "print(\"CNN2D Model Saved\")\n",
    "train_hist_m3 = pd.DataFrame(CNN2D_Results.history)\n",
    "train_m3 = round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bcf1a2",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e996553",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m3[[\"loss\", \"val_loss\"]])\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m3[[\"accuracy\", \"val_accuracy\"]])\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.title(\"Accuracy Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31334829",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m3 = CNN2D_Model.evaluate(xtest, yTest, verbose=0)\n",
    "t0 = time.time()\n",
    "y_pred_m3 = CNN2D_Model.predict(xtest, verbose=0)\n",
    "pred_m3 = round(time.time() - t0, 3)\n",
    "log_entry = pd.DataFrame(\n",
    "    [[\"CNN2D\", acc_m3[1] * 100, train_m3, pred_m3]], columns=log_cols\n",
    ")\n",
    "log = log.append(log_entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864e81f",
   "metadata": {
    "papermill": {
     "duration": 2.034009,
     "end_time": "2021-05-18T14:03:41.813463",
     "exception": false,
     "start_time": "2021-05-18T14:03:39.779454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN2D Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict the feature\n",
    "def CNN2D_Prediction(file_name):\n",
    "    # load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    # get the feature\n",
    "    feature = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=128)\n",
    "    # scale the features\n",
    "    feature_scaled = np.mean(feature.T, axis=0)\n",
    "    # array of features\n",
    "    prediction_feature = np.array([feature_scaled])\n",
    "    # reshaping the features\n",
    "    final_prediction_feature = prediction_feature.reshape(\n",
    "        prediction_feature.shape[0], 16, 8, 1\n",
    "    )\n",
    "    # get the id of label using argmax\n",
    "    predicted_vector = np.argmax(CNN2D_Model.predict(final_prediction_feature), axis=-1)\n",
    "    # get the class label from class id\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    # display the result\n",
    "    print(\"CNN2D has predicted the class as  --> \", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d9ab9",
   "metadata": {
    "papermill": {
     "duration": 2.014985,
     "end_time": "2021-05-18T14:03:59.338044",
     "exception": false,
     "start_time": "2021-05-18T14:03:57.323059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05332373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name\n",
    "file_name = audio_dataset_path + \"fold8/103076-3-0-0.wav\"\n",
    "# get the output\n",
    "CNN2D_Prediction(file_name)\n",
    "# play the file\n",
    "ipd.Audio(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03187c",
   "metadata": {},
   "source": [
    "# **Comparative Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (17, 2)\n",
    "plt.rcParams[\"figure.dpi\"] = 550\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"accuracy\", y=\"model\", data=log, color=\"b\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1478af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"train_time\", y=\"model\", data=log, color=\"r\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Training Time\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.title(\"Model Training Time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd72200",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"pred_time\", y=\"model\", data=log, color=\"g\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Prediction Time\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.title(\"Model Prediction Time\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1112.254412,
   "end_time": "2021-05-18T14:04:08.302216",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-18T13:45:36.047804",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
